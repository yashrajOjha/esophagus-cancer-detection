{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# VGG16","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom glob import glob\nimport matplotlib.pyplot as plt\n\n# from keras.optimizers import SGD, RMSprop\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nimport tensorflow as tf\nimport cv2\nimport glob\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom tensorflow.python.keras import backend as K\nimport plotly.graph_objects as go\nimport plotly.offline as py\nautosize =False\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:53:43.121600Z","iopub.execute_input":"2023-01-05T14:53:43.122193Z","iopub.status.idle":"2023-01-05T14:53:43.132588Z","shell.execute_reply.started":"2023-01-05T14:53:43.122161Z","shell.execute_reply":"2023-01-05T14:53:43.131605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.load('/kaggle/input/esophageal-endoscopy-images-resized/esophagus-cancer-files/x_train_128.npy')\nx_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:53:45.916516Z","iopub.execute_input":"2023-01-05T14:53:45.918629Z","iopub.status.idle":"2023-01-05T14:53:50.597534Z","shell.execute_reply.started":"2023-01-05T14:53:45.918582Z","shell.execute_reply":"2023-01-05T14:53:50.596516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = pd.read_csv('/kaggle/input/esophageal-endoscopy-images-resized/esophagus-cancer-files/traindata.csv').target\ny.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:53:58.339473Z","iopub.execute_input":"2023-01-05T14:53:58.340839Z","iopub.status.idle":"2023-01-05T14:53:58.447122Z","shell.execute_reply.started":"2023-01-05T14:53:58.340800Z","shell.execute_reply":"2023-01-05T14:53:58.444270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import class_weight\n \nclass_weights = class_weight.compute_class_weight(class_weight=\"balanced\",classes=np.unique(y),y=y)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:00.951071Z","iopub.execute_input":"2023-01-05T14:54:00.951649Z","iopub.status.idle":"2023-01-05T14:54:01.483167Z","shell.execute_reply.started":"2023-01-05T14:54:00.951603Z","shell.execute_reply":"2023-01-05T14:54:01.482020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights = dict(enumerate(class_weights))\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:02.312935Z","iopub.execute_input":"2023-01-05T14:54:02.313416Z","iopub.status.idle":"2023-01-05T14:54:02.327829Z","shell.execute_reply.started":"2023-01-05T14:54:02.313375Z","shell.execute_reply":"2023-01-05T14:54:02.326496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting the dataset\nfrom sklearn.model_selection import train_test_split\ntrain_imgs, validation_imgs, y_train, y_val = train_test_split(x_train,y, test_size=0.2, random_state=1234)\ntrain_imgs, test_imgs, y_train, y_test = train_test_split(train_imgs,y_train, test_size=0.1, random_state=1234)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:04.681235Z","iopub.execute_input":"2023-01-05T14:54:04.681736Z","iopub.status.idle":"2023-01-05T14:54:05.009597Z","shell.execute_reply.started":"2023-01-05T14:54:04.681689Z","shell.execute_reply":"2023-01-05T14:54:05.008599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:06.528334Z","iopub.execute_input":"2023-01-05T14:54:06.529375Z","iopub.status.idle":"2023-01-05T14:54:06.536438Z","shell.execute_reply.started":"2023-01-05T14:54:06.529295Z","shell.execute_reply":"2023-01-05T14:54:06.535332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nnum_classes = 2\nepochs = 50\ninput_shape = (128,128,3)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:08.715423Z","iopub.execute_input":"2023-01-05T14:54:08.716115Z","iopub.status.idle":"2023-01-05T14:54:08.721360Z","shell.execute_reply.started":"2023-01-05T14:54:08.716072Z","shell.execute_reply":"2023-01-05T14:54:08.720303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(lr=1e-5)\n\nnb_train_steps = train_imgs.shape[0]//batch_size\nnb_val_steps=validation_imgs.shape[0]//batch_size\n\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:10.991142Z","iopub.execute_input":"2023-01-05T14:54:10.991520Z","iopub.status.idle":"2023-01-05T14:54:11.005914Z","shell.execute_reply.started":"2023-01-05T14:54:10.991488Z","shell.execute_reply":"2023-01-05T14:54:11.004920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True, fill_mode='nearest')\n\n# no need to create augmentation images for validation data, only rescaling the pixels\nval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow(train_imgs, y_train, batch_size=32)\nval_generator = val_datagen.flow(validation_imgs, y_val, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:14.235872Z","iopub.execute_input":"2023-01-05T14:54:14.236225Z","iopub.status.idle":"2023-01-05T14:54:14.704020Z","shell.execute_reply.started":"2023-01-05T14:54:14.236195Z","shell.execute_reply":"2023-01-05T14:54:14.703038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Activating the trainable layers","metadata":{}},{"cell_type":"code","source":"from keras.applications import vgg16\nfrom keras.models import Model\nimport keras\n\nvgg = vgg16.VGG16(include_top=False, weights='imagenet', \n                                     input_shape=input_shape)\n\noutput = vgg.layers[-1].output\noutput = keras.layers.Flatten()(output)\nvgg_model = Model(vgg.input, output)\n\nvgg_model.trainable = False\nfor layer in vgg_model.layers:\n    layer.trainable = False\n    \nimport pandas as pd\npd.set_option('max_colwidth', -1)\nlayers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])  ","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:19.484128Z","iopub.execute_input":"2023-01-05T14:54:19.484506Z","iopub.status.idle":"2023-01-05T14:54:23.085336Z","shell.execute_reply.started":"2023-01-05T14:54:19.484473Z","shell.execute_reply":"2023-01-05T14:54:23.084361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model.trainable = True\n\nset_trainable = False\nfor layer in vgg_model.layers:\n    if layer.name in ['block5_conv1', 'block4_conv1']:\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n        \nlayers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) ","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:27.517048Z","iopub.execute_input":"2023-01-05T14:54:27.517968Z","iopub.status.idle":"2023-01-05T14:54:27.542219Z","shell.execute_reply.started":"2023-01-05T14:54:27.517925Z","shell.execute_reply":"2023-01-05T14:54:27.541342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding layers for classification","metadata":{}},{"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\nfrom keras.models import Sequential\nfrom keras import optimizers\n\nmodel = Sequential()\nmodel.add(vgg_model)\nmodel.add(Dense(512, activation='relu', input_dim=input_shape))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC()],optimizer=opt)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:30.283515Z","iopub.execute_input":"2023-01-05T14:54:30.283866Z","iopub.status.idle":"2023-01-05T14:54:30.380555Z","shell.execute_reply.started":"2023-01-05T14:54:30.283837Z","shell.execute_reply":"2023-01-05T14:54:30.379646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:31.349241Z","iopub.execute_input":"2023-01-05T14:54:31.350602Z","iopub.status.idle":"2023-01-05T14:54:31.358170Z","shell.execute_reply.started":"2023-01-05T14:54:31.350557Z","shell.execute_reply":"2023-01-05T14:54:31.357144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_generator, steps_per_epoch=nb_train_steps, epochs=epochs,\n                              validation_data=val_generator, validation_steps=nb_val_steps,class_weight=class_weights, \n                              verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T14:54:34.684479Z","iopub.execute_input":"2023-01-05T14:54:34.684864Z","iopub.status.idle":"2023-01-05T15:02:25.644078Z","shell.execute_reply.started":"2023-01-05T14:54:34.684830Z","shell.execute_reply":"2023-01-05T15:02:25.643097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#saving model\nimport tensorflow as tf\nmodel.save('vgg-esophagus-model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:03:29.592053Z","iopub.execute_input":"2023-01-05T15:03:29.592431Z","iopub.status.idle":"2023-01-05T15:03:29.977487Z","shell.execute_reply.started":"2023-01-05T15:03:29.592398Z","shell.execute_reply":"2023-01-05T15:03:29.976369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import expand_dims\ndef tta_prediction(datagen, model, image, n_examples):\n    # convert image into dataset\n    samples = expand_dims(image, 0)\n    # prepare iterator\n    it = datagen.flow(samples, batch_size=n_examples)\n    # make predictions for each augmented image\n    probs = model.predict_generator(it, steps=n_examples, verbose=0)\n    #print(len(probs))    \n    prob = np.mean(probs, axis=1)    \n    return prob","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:08:00.453482Z","iopub.execute_input":"2023-01-05T15:08:00.453877Z","iopub.status.idle":"2023-01-05T15:08:00.461763Z","shell.execute_reply.started":"2023-01-05T15:08:00.453845Z","shell.execute_reply":"2023-01-05T15:08:00.460542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n# configure image data augmentation\ntest_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True, fill_mode='nearest')","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:08:01.557268Z","iopub.execute_input":"2023-01-05T15:08:01.558139Z","iopub.status.idle":"2023-01-05T15:08:01.563862Z","shell.execute_reply.started":"2023-01-05T15:08:01.558100Z","shell.execute_reply":"2023-01-05T15:08:01.562745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:08:03.058097Z","iopub.execute_input":"2023-01-05T15:08:03.058763Z","iopub.status.idle":"2023-01-05T15:08:03.065232Z","shell.execute_reply.started":"2023-01-05T15:08:03.058725Z","shell.execute_reply":"2023-01-05T15:08:03.064259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targetvalues=[]\n#i = 0\nfor img in tqdm(test_imgs):\n    prediction=tta_prediction(test_datagen,model,img,32)\n    pred_y = prediction[0]\n    val=0\n    if pred_y>0.5:\n        val=1\n    targetvalues.append(val)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:08:04.307221Z","iopub.execute_input":"2023-01-05T15:08:04.308085Z","iopub.status.idle":"2023-01-05T15:08:52.996776Z","shell.execute_reply.started":"2023-01-05T15:08:04.308039Z","shell.execute_reply":"2023-01-05T15:08:52.995757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\nprint(confusion_matrix(y_test, targetvalues))\nprint(classification_report(y_test, targetvalues))","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:10:45.455858Z","iopub.execute_input":"2023-01-05T15:10:45.456230Z","iopub.status.idle":"2023-01-05T15:10:45.470555Z","shell.execute_reply.started":"2023-01-05T15:10:45.456197Z","shell.execute_reply":"2023-01-05T15:10:45.469168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Manual Testing","metadata":{}},{"cell_type":"code","source":"from PIL import Image\ndef preprocess_image(image_path, desired_size=128):\n    im = Image.open(image_path)\n    im = im.resize((desired_size, )*2, resample=Image.LANCZOS)\n    return im","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:18:53.306389Z","iopub.execute_input":"2023-01-05T15:18:53.306849Z","iopub.status.idle":"2023-01-05T15:18:53.317463Z","shell.execute_reply.started":"2023-01-05T15:18:53.306810Z","shell.execute_reply":"2023-01-05T15:18:53.316303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nesotest = '/kaggle/input/esophagustestset/test/esophagus'\nnoesotest = '/kaggle/input/esophagustestset/test/no-esophagus'\nesotestlist = os.listdir(esotest)\nnoesotestlist = os.listdir(noesotest)\ntestlist = []\nfor name in esotestlist:\n    testlist.append(esotest+'/'+name)\nfor name in noesotestlist:\n    testlist.append(noesotest+'/'+name)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:12:06.938650Z","iopub.execute_input":"2023-01-05T15:12:06.939103Z","iopub.status.idle":"2023-01-05T15:12:06.950561Z","shell.execute_reply.started":"2023-01-05T15:12:06.939063Z","shell.execute_reply":"2023-01-05T15:12:06.949447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testlabels = []\nfor i in range(40):\n    if i<20:\n        testlabels.append(1)\n    else:\n        testlabels.append(0)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:15:42.690023Z","iopub.execute_input":"2023-01-05T15:15:42.690406Z","iopub.status.idle":"2023-01-05T15:15:42.695594Z","shell.execute_reply.started":"2023-01-05T15:15:42.690373Z","shell.execute_reply":"2023-01-05T15:15:42.694383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = 40\nimSize = 128\n# create an empty matrix for storing the images\ntestset = np.empty((40, imSize, imSize, 3), dtype=np.uint8)\n\n# loop through the images from the images ids from the target\\id dataset\n# then grab the cooresponding image from disk, pre-process, and store in matrix in memory\nfor i, image_id in enumerate(tqdm(testlist)):\n    testset[i, :, :, :] = preprocess_image(\n        image_id\n    )","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:18:57.295812Z","iopub.execute_input":"2023-01-05T15:18:57.296170Z","iopub.status.idle":"2023-01-05T15:18:58.742828Z","shell.execute_reply.started":"2023-01-05T15:18:57.296139Z","shell.execute_reply":"2023-01-05T15:18:58.741843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predval = []\nfor img in tqdm(testset):\n    prediction=tta_prediction(test_datagen,model,img,1)\n    pred_y = prediction[0]\n    val=0\n    if pred_y>0.5:\n        val=1\n    predval.append(val)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:20:23.640639Z","iopub.execute_input":"2023-01-05T15:20:23.640996Z","iopub.status.idle":"2023-01-05T15:20:25.620741Z","shell.execute_reply.started":"2023-01-05T15:20:23.640965Z","shell.execute_reply":"2023-01-05T15:20:25.619177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testing the model accuracy manually","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\nprint(accuracy_score(testlabels,predval)*100)\nprint(confusion_matrix(testlabels, predval))","metadata":{"execution":{"iopub.status.busy":"2023-01-05T15:23:24.153066Z","iopub.execute_input":"2023-01-05T15:23:24.153454Z","iopub.status.idle":"2023-01-05T15:23:24.161199Z","shell.execute_reply.started":"2023-01-05T15:23:24.153421Z","shell.execute_reply":"2023-01-05T15:23:24.160166Z"},"trusted":true},"execution_count":null,"outputs":[]}]}