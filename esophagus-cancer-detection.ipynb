{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yashrajojha28/esophagus-cancer-detection?scriptVersionId=116087758\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# VGG16","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom glob import glob\nimport matplotlib.pyplot as plt\n\n# from keras.optimizers import SGD, RMSprop\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nimport tensorflow as tf\nimport cv2\nimport glob\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom tensorflow.python.keras import backend as K\nimport plotly.graph_objects as go\nimport plotly.offline as py\nautosize =False\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:21.584327Z","iopub.execute_input":"2023-01-11T12:33:21.584726Z","iopub.status.idle":"2023-01-11T12:33:26.866895Z","shell.execute_reply.started":"2023-01-11T12:33:21.584644Z","shell.execute_reply":"2023-01-11T12:33:26.865977Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"x_train = np.load('/kaggle/input/esophageal-endoscopy-images-resized/esophagus-cancer-files/x_train_128.npy')\nx_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:26.868735Z","iopub.execute_input":"2023-01-11T12:33:26.869447Z","iopub.status.idle":"2023-01-11T12:33:31.47328Z","shell.execute_reply.started":"2023-01-11T12:33:26.869412Z","shell.execute_reply":"2023-01-11T12:33:31.47238Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(10662, 128, 128, 3)"},"metadata":{}}]},{"cell_type":"code","source":"y = pd.read_csv('/kaggle/input/esophageal-endoscopy-images-resized/esophagus-cancer-files/traindata.csv').target\ny.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:31.474788Z","iopub.execute_input":"2023-01-11T12:33:31.475312Z","iopub.status.idle":"2023-01-11T12:33:31.521879Z","shell.execute_reply.started":"2023-01-11T12:33:31.475272Z","shell.execute_reply":"2023-01-11T12:33:31.520768Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(10662,)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.utils import class_weight\n \nclass_weights = class_weight.compute_class_weight(class_weight=\"balanced\",classes=np.unique(y),y=y)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:31.524735Z","iopub.execute_input":"2023-01-11T12:33:31.52511Z","iopub.status.idle":"2023-01-11T12:33:31.913298Z","shell.execute_reply.started":"2023-01-11T12:33:31.525073Z","shell.execute_reply":"2023-01-11T12:33:31.91231Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class_weights = dict(enumerate(class_weights))\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:31.914913Z","iopub.execute_input":"2023-01-11T12:33:31.915326Z","iopub.status.idle":"2023-01-11T12:33:31.92421Z","shell.execute_reply.started":"2023-01-11T12:33:31.915288Z","shell.execute_reply":"2023-01-11T12:33:31.92318Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{0: 0.5941156803744567, 1: 3.1563055062166963}"},"metadata":{}}]},{"cell_type":"code","source":"#splitting the dataset\nfrom sklearn.model_selection import train_test_split\ntrain_imgs, validation_imgs, y_train, y_val = train_test_split(x_train,y, test_size=0.2, random_state=1234)\ntrain_imgs, test_imgs, y_train, y_test = train_test_split(train_imgs,y_train, test_size=0.1, random_state=1234)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:31.925849Z","iopub.execute_input":"2023-01-11T12:33:31.926306Z","iopub.status.idle":"2023-01-11T12:33:32.25189Z","shell.execute_reply.started":"2023-01-11T12:33:31.926268Z","shell.execute_reply":"2023-01-11T12:33:32.250922Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_imgs.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:32.25328Z","iopub.execute_input":"2023-01-11T12:33:32.253852Z","iopub.status.idle":"2023-01-11T12:33:32.263368Z","shell.execute_reply.started":"2023-01-11T12:33:32.253815Z","shell.execute_reply":"2023-01-11T12:33:32.262311Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(853, 128, 128, 3)"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 128\nnum_classes = 2\nepochs = 50\ninput_shape = (128,128,3)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:32.265307Z","iopub.execute_input":"2023-01-11T12:33:32.265935Z","iopub.status.idle":"2023-01-11T12:33:32.27195Z","shell.execute_reply.started":"2023-01-11T12:33:32.2659Z","shell.execute_reply":"2023-01-11T12:33:32.271019Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"opt = Adam(lr=1e-5)\n\nnb_train_steps = train_imgs.shape[0]//batch_size\nnb_val_steps=validation_imgs.shape[0]//batch_size\n\nprint(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:32.273432Z","iopub.execute_input":"2023-01-11T12:33:32.274216Z","iopub.status.idle":"2023-01-11T12:33:32.291007Z","shell.execute_reply.started":"2023-01-11T12:33:32.27418Z","shell.execute_reply":"2023-01-11T12:33:32.289995Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number of training and validation steps: 59 and 16\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True, fill_mode='nearest')\n\n# no need to create augmentation images for validation data, only rescaling the pixels\nval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow(train_imgs, y_train, batch_size=32)\nval_generator = val_datagen.flow(validation_imgs, y_val, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:32.295319Z","iopub.execute_input":"2023-01-11T12:33:32.29557Z","iopub.status.idle":"2023-01-11T12:33:32.763007Z","shell.execute_reply.started":"2023-01-11T12:33:32.295547Z","shell.execute_reply":"2023-01-11T12:33:32.761678Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Activating the trainable layers","metadata":{}},{"cell_type":"code","source":"from keras.applications import vgg16\nfrom keras.models import Model\nimport keras\n\nvgg = vgg16.VGG16(include_top=False, weights='imagenet', \n                                     input_shape=input_shape)\n\noutput = vgg.layers[-1].output\noutput = keras.layers.Flatten()(output)\nvgg_model = Model(vgg.input, output)\n\nvgg_model.trainable = False\nfor layer in vgg_model.layers:\n    layer.trainable = False\n    \nimport pandas as pd\npd.set_option('max_colwidth', -1)\nlayers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])  ","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:32.765765Z","iopub.execute_input":"2023-01-11T12:33:32.766454Z","iopub.status.idle":"2023-01-11T12:33:38.343456Z","shell.execute_reply.started":"2023-01-11T12:33:32.766383Z","shell.execute_reply":"2023-01-11T12:33:38.342488Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2023-01-11 12:33:32.872656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-11 12:33:33.077614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-11 12:33:33.078475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-11 12:33:33.080583: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-11 12:33:33.080921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-11 12:33:33.081669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-11 12:33:33.082430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-11 12:33:35.221416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-11 12:33:35.222286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-11 12:33:35.223303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-11 12:33:35.223901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 2s 0us/step\n58900480/58889256 [==============================] - 2s 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning:\n\nPassing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                        Layer Type  \\\n0   <keras.engine.input_layer.InputLayer object at 0x7f343572c310>   \n1   <keras.layers.convolutional.Conv2D object at 0x7f3434d34f10>     \n2   <keras.layers.convolutional.Conv2D object at 0x7f34bd9a2d10>     \n3   <keras.layers.pooling.MaxPooling2D object at 0x7f3434c9e550>     \n4   <keras.layers.convolutional.Conv2D object at 0x7f3434cac710>     \n5   <keras.layers.convolutional.Conv2D object at 0x7f3434cacb10>     \n6   <keras.layers.pooling.MaxPooling2D object at 0x7f3434b365d0>     \n7   <keras.layers.convolutional.Conv2D object at 0x7f3434b3ad90>     \n8   <keras.layers.convolutional.Conv2D object at 0x7f3434b409d0>     \n9   <keras.layers.convolutional.Conv2D object at 0x7f3434cb0d10>     \n10  <keras.layers.pooling.MaxPooling2D object at 0x7f3434b4b2d0>     \n11  <keras.layers.convolutional.Conv2D object at 0x7f3434b50590>     \n12  <keras.layers.convolutional.Conv2D object at 0x7f3434b4b250>     \n13  <keras.layers.convolutional.Conv2D object at 0x7f3434b58d90>     \n14  <keras.layers.pooling.MaxPooling2D object at 0x7f3434b63290>     \n15  <keras.layers.convolutional.Conv2D object at 0x7f3434b5e610>     \n16  <keras.layers.convolutional.Conv2D object at 0x7f3434b49b10>     \n17  <keras.layers.convolutional.Conv2D object at 0x7f3434b6bd90>     \n18  <keras.layers.pooling.MaxPooling2D object at 0x7f3434cf5e10>     \n19  <keras.layers.core.Flatten object at 0x7f3434bec7d0>             \n\n      Layer Name  Layer Trainable  \n0   input_1       False            \n1   block1_conv1  False            \n2   block1_conv2  False            \n3   block1_pool   False            \n4   block2_conv1  False            \n5   block2_conv2  False            \n6   block2_pool   False            \n7   block3_conv1  False            \n8   block3_conv2  False            \n9   block3_conv3  False            \n10  block3_pool   False            \n11  block4_conv1  False            \n12  block4_conv2  False            \n13  block4_conv3  False            \n14  block4_pool   False            \n15  block5_conv1  False            \n16  block5_conv2  False            \n17  block5_conv3  False            \n18  block5_pool   False            \n19  flatten       False            ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Layer Type</th>\n      <th>Layer Name</th>\n      <th>Layer Trainable</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;keras.engine.input_layer.InputLayer object at 0x7f343572c310&gt;</td>\n      <td>input_1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434d34f10&gt;</td>\n      <td>block1_conv1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f34bd9a2d10&gt;</td>\n      <td>block1_conv2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434c9e550&gt;</td>\n      <td>block1_pool</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434cac710&gt;</td>\n      <td>block2_conv1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434cacb10&gt;</td>\n      <td>block2_conv2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434b365d0&gt;</td>\n      <td>block2_pool</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b3ad90&gt;</td>\n      <td>block3_conv1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b409d0&gt;</td>\n      <td>block3_conv2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434cb0d10&gt;</td>\n      <td>block3_conv3</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434b4b2d0&gt;</td>\n      <td>block3_pool</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b50590&gt;</td>\n      <td>block4_conv1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b4b250&gt;</td>\n      <td>block4_conv2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b58d90&gt;</td>\n      <td>block4_conv3</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434b63290&gt;</td>\n      <td>block4_pool</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b5e610&gt;</td>\n      <td>block5_conv1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b49b10&gt;</td>\n      <td>block5_conv2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b6bd90&gt;</td>\n      <td>block5_conv3</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434cf5e10&gt;</td>\n      <td>block5_pool</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>&lt;keras.layers.core.Flatten object at 0x7f3434bec7d0&gt;</td>\n      <td>flatten</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"vgg_model.trainable = True\n\nset_trainable = False\nfor layer in vgg_model.layers:\n    if layer.name in ['block5_conv1', 'block4_conv1']:\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n        \nlayers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) ","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:38.347667Z","iopub.execute_input":"2023-01-11T12:33:38.349905Z","iopub.status.idle":"2023-01-11T12:33:38.373161Z","shell.execute_reply.started":"2023-01-11T12:33:38.349856Z","shell.execute_reply":"2023-01-11T12:33:38.372262Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                        Layer Type  \\\n0   <keras.engine.input_layer.InputLayer object at 0x7f343572c310>   \n1   <keras.layers.convolutional.Conv2D object at 0x7f3434d34f10>     \n2   <keras.layers.convolutional.Conv2D object at 0x7f34bd9a2d10>     \n3   <keras.layers.pooling.MaxPooling2D object at 0x7f3434c9e550>     \n4   <keras.layers.convolutional.Conv2D object at 0x7f3434cac710>     \n5   <keras.layers.convolutional.Conv2D object at 0x7f3434cacb10>     \n6   <keras.layers.pooling.MaxPooling2D object at 0x7f3434b365d0>     \n7   <keras.layers.convolutional.Conv2D object at 0x7f3434b3ad90>     \n8   <keras.layers.convolutional.Conv2D object at 0x7f3434b409d0>     \n9   <keras.layers.convolutional.Conv2D object at 0x7f3434cb0d10>     \n10  <keras.layers.pooling.MaxPooling2D object at 0x7f3434b4b2d0>     \n11  <keras.layers.convolutional.Conv2D object at 0x7f3434b50590>     \n12  <keras.layers.convolutional.Conv2D object at 0x7f3434b4b250>     \n13  <keras.layers.convolutional.Conv2D object at 0x7f3434b58d90>     \n14  <keras.layers.pooling.MaxPooling2D object at 0x7f3434b63290>     \n15  <keras.layers.convolutional.Conv2D object at 0x7f3434b5e610>     \n16  <keras.layers.convolutional.Conv2D object at 0x7f3434b49b10>     \n17  <keras.layers.convolutional.Conv2D object at 0x7f3434b6bd90>     \n18  <keras.layers.pooling.MaxPooling2D object at 0x7f3434cf5e10>     \n19  <keras.layers.core.Flatten object at 0x7f3434bec7d0>             \n\n      Layer Name  Layer Trainable  \n0   input_1       False            \n1   block1_conv1  False            \n2   block1_conv2  False            \n3   block1_pool   False            \n4   block2_conv1  False            \n5   block2_conv2  False            \n6   block2_pool   False            \n7   block3_conv1  False            \n8   block3_conv2  False            \n9   block3_conv3  False            \n10  block3_pool   False            \n11  block4_conv1  True             \n12  block4_conv2  True             \n13  block4_conv3  True             \n14  block4_pool   True             \n15  block5_conv1  True             \n16  block5_conv2  True             \n17  block5_conv3  True             \n18  block5_pool   True             \n19  flatten       True             ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Layer Type</th>\n      <th>Layer Name</th>\n      <th>Layer Trainable</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;keras.engine.input_layer.InputLayer object at 0x7f343572c310&gt;</td>\n      <td>input_1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434d34f10&gt;</td>\n      <td>block1_conv1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f34bd9a2d10&gt;</td>\n      <td>block1_conv2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434c9e550&gt;</td>\n      <td>block1_pool</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434cac710&gt;</td>\n      <td>block2_conv1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434cacb10&gt;</td>\n      <td>block2_conv2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434b365d0&gt;</td>\n      <td>block2_pool</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b3ad90&gt;</td>\n      <td>block3_conv1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b409d0&gt;</td>\n      <td>block3_conv2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434cb0d10&gt;</td>\n      <td>block3_conv3</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434b4b2d0&gt;</td>\n      <td>block3_pool</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b50590&gt;</td>\n      <td>block4_conv1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b4b250&gt;</td>\n      <td>block4_conv2</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b58d90&gt;</td>\n      <td>block4_conv3</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434b63290&gt;</td>\n      <td>block4_pool</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b5e610&gt;</td>\n      <td>block5_conv1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b49b10&gt;</td>\n      <td>block5_conv2</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f3434b6bd90&gt;</td>\n      <td>block5_conv3</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f3434cf5e10&gt;</td>\n      <td>block5_pool</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>&lt;keras.layers.core.Flatten object at 0x7f3434bec7d0&gt;</td>\n      <td>flatten</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Adding layers for classification","metadata":{}},{"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\nfrom keras.models import Sequential\nfrom keras import optimizers\n\nmodel = Sequential()\nmodel.add(vgg_model)\nmodel.add(Dense(512, activation='relu', input_dim=input_shape))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC()],optimizer=opt)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:38.377257Z","iopub.execute_input":"2023-01-11T12:33:38.379619Z","iopub.status.idle":"2023-01-11T12:33:38.517972Z","shell.execute_reply.started":"2023-01-11T12:33:38.37958Z","shell.execute_reply":"2023-01-11T12:33:38.516892Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:38.522982Z","iopub.execute_input":"2023-01-11T12:33:38.52552Z","iopub.status.idle":"2023-01-11T12:33:38.538972Z","shell.execute_reply.started":"2023-01-11T12:33:38.52548Z","shell.execute_reply":"2023-01-11T12:33:38.537566Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmodel (Functional)           (None, 8192)              14714688  \n_________________________________________________________________\ndense (Dense)                (None, 512)               4194816   \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 19,172,673\nTrainable params: 17,437,185\nNon-trainable params: 1,735,488\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit_generator(train_generator, steps_per_epoch=nb_train_steps, epochs=epochs,\n                              validation_data=val_generator, validation_steps=nb_val_steps,class_weight=class_weights, \n                              verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:33:38.543727Z","iopub.execute_input":"2023-01-11T12:33:38.546319Z","iopub.status.idle":"2023-01-11T12:41:46.627014Z","shell.execute_reply.started":"2023-01-11T12:33:38.546277Z","shell.execute_reply":"2023-01-11T12:41:46.625821Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning:\n\n`Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n\n2023-01-11 12:33:38.830682: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2023-01-11 12:33:41.580584: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"59/59 [==============================] - 19s 167ms/step - loss: 0.4920 - auc: 0.8371 - val_loss: 0.2051 - val_auc: 0.9770\nEpoch 2/50\n59/59 [==============================] - 8s 134ms/step - loss: 0.2250 - auc: 0.9619 - val_loss: 0.1412 - val_auc: 0.9839\nEpoch 3/50\n59/59 [==============================] - 8s 137ms/step - loss: 0.1281 - auc: 0.9901 - val_loss: 0.0968 - val_auc: 0.9977\nEpoch 4/50\n59/59 [==============================] - 8s 134ms/step - loss: 0.1231 - auc: 0.9884 - val_loss: 0.0566 - val_auc: 0.9960\nEpoch 5/50\n59/59 [==============================] - 8s 129ms/step - loss: 0.0887 - auc: 0.9939 - val_loss: 0.0599 - val_auc: 0.9978\nEpoch 6/50\n59/59 [==============================] - 8s 131ms/step - loss: 0.1042 - auc: 0.9922 - val_loss: 0.0341 - val_auc: 0.9988\nEpoch 7/50\n59/59 [==============================] - 8s 136ms/step - loss: 0.0797 - auc: 0.9947 - val_loss: 0.0695 - val_auc: 0.9932\nEpoch 8/50\n59/59 [==============================] - 9s 144ms/step - loss: 0.0864 - auc: 0.9933 - val_loss: 0.0459 - val_auc: 0.9980\nEpoch 9/50\n59/59 [==============================] - 8s 136ms/step - loss: 0.0681 - auc: 0.9956 - val_loss: 0.0534 - val_auc: 0.9979\nEpoch 10/50\n59/59 [==============================] - 8s 131ms/step - loss: 0.0661 - auc: 0.9967 - val_loss: 0.0381 - val_auc: 0.9985\nEpoch 11/50\n59/59 [==============================] - 8s 133ms/step - loss: 0.1045 - auc: 0.9914 - val_loss: 0.0526 - val_auc: 0.9989\nEpoch 12/50\n59/59 [==============================] - 8s 131ms/step - loss: 0.0615 - auc: 0.9973 - val_loss: 0.0366 - val_auc: 0.9985\nEpoch 13/50\n59/59 [==============================] - 8s 138ms/step - loss: 0.0688 - auc: 0.9959 - val_loss: 0.0210 - val_auc: 0.9995\nEpoch 14/50\n59/59 [==============================] - 8s 140ms/step - loss: 0.0489 - auc: 0.9978 - val_loss: 0.0144 - val_auc: 0.9997\nEpoch 15/50\n59/59 [==============================] - 8s 134ms/step - loss: 0.0434 - auc: 0.9980 - val_loss: 0.0118 - val_auc: 0.9999\nEpoch 16/50\n59/59 [==============================] - 8s 137ms/step - loss: 0.0394 - auc: 0.9984 - val_loss: 0.0378 - val_auc: 0.9999\nEpoch 17/50\n59/59 [==============================] - 8s 134ms/step - loss: 0.0386 - auc: 0.9987 - val_loss: 0.0137 - val_auc: 0.9998\nEpoch 18/50\n59/59 [==============================] - 8s 144ms/step - loss: 0.0360 - auc: 0.9991 - val_loss: 0.0266 - val_auc: 0.9936\nEpoch 19/50\n59/59 [==============================] - 8s 135ms/step - loss: 0.0379 - auc: 0.9980 - val_loss: 0.0096 - val_auc: 0.9999\nEpoch 20/50\n59/59 [==============================] - 8s 131ms/step - loss: 0.0446 - auc: 0.9980 - val_loss: 0.0199 - val_auc: 0.9996\nEpoch 21/50\n59/59 [==============================] - 8s 142ms/step - loss: 0.0408 - auc: 0.9987 - val_loss: 0.0184 - val_auc: 0.9998\nEpoch 22/50\n59/59 [==============================] - 8s 134ms/step - loss: 0.0488 - auc: 0.9985 - val_loss: 0.0477 - val_auc: 1.0000\nEpoch 23/50\n59/59 [==============================] - 8s 136ms/step - loss: 0.0471 - auc: 0.9979 - val_loss: 0.0056 - val_auc: 1.0000\nEpoch 24/50\n59/59 [==============================] - 8s 133ms/step - loss: 0.0502 - auc: 0.9978 - val_loss: 0.0460 - val_auc: 0.9988\nEpoch 25/50\n59/59 [==============================] - 8s 138ms/step - loss: 0.0302 - auc: 0.9991 - val_loss: 0.0123 - val_auc: 1.0000\nEpoch 26/50\n59/59 [==============================] - 8s 129ms/step - loss: 0.0273 - auc: 0.9993 - val_loss: 0.0362 - val_auc: 1.0000\n53/59 [=========================>....] - ETA: 0s - loss: 0.0309 - auc: 0.9984Epoch 37/50\n59/59 [==============================] - 8s 134ms/step - loss: 0.0406 - auc: 0.9988 - val_loss: 0.0045 - val_auc: 1.0000\nEpoch 38/50\n59/59 [==============================] - 8s 143ms/step - loss: 0.0154 - auc: 0.9997 - val_loss: 0.0202 - val_auc: 0.9997\nEpoch 39/50\n59/59 [==============================] - 8s 135ms/step - loss: 0.0270 - auc: 0.9992 - val_loss: 0.0340 - val_auc: 0.9998\nEpoch 40/50\n59/59 [==============================] - 8s 133ms/step - loss: 0.0252 - auc: 0.9996 - val_loss: 0.0147 - val_auc: 0.9999\nEpoch 41/50\n59/59 [==============================] - 8s 138ms/step - loss: 0.0132 - auc: 0.9995 - val_loss: 0.0031 - val_auc: 1.0000\nEpoch 42/50\n59/59 [==============================] - 8s 131ms/step - loss: 0.0186 - auc: 0.9998 - val_loss: 0.0044 - val_auc: 1.0000\nEpoch 43/50\n59/59 [==============================] - 8s 134ms/step - loss: 0.0148 - auc: 0.9999 - val_loss: 0.0053 - val_auc: 1.0000\nEpoch 44/50\n59/59 [==============================] - 8s 143ms/step - loss: 0.0232 - auc: 0.9989 - val_loss: 0.0091 - val_auc: 0.9999\nEpoch 45/50\n59/59 [==============================] - 8s 136ms/step - loss: 0.0282 - auc: 0.9995 - val_loss: 0.0077 - val_auc: 0.9999\nEpoch 46/50\n59/59 [==============================] - 8s 138ms/step - loss: 0.0193 - auc: 0.9997 - val_loss: 0.0281 - val_auc: 0.9999\nEpoch 47/50\n59/59 [==============================] - 8s 131ms/step - loss: 0.0223 - auc: 0.9996 - val_loss: 0.0050 - val_auc: 1.0000\nEpoch 48/50\n59/59 [==============================] - 8s 140ms/step - loss: 0.0141 - auc: 0.9999 - val_loss: 0.0062 - val_auc: 1.0000\nEpoch 49/50\n59/59 [==============================] - 8s 136ms/step - loss: 0.0197 - auc: 0.9994 - val_loss: 0.0045 - val_auc: 1.0000\nEpoch 50/50\n59/59 [==============================] - 8s 135ms/step - loss: 0.0270 - auc: 0.9986 - val_loss: 0.0197 - val_auc: 0.9997\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f3434c4b550>"},"metadata":{}}]},{"cell_type":"code","source":"#saving model\nimport tensorflow as tf\nmodel.save('vgg-esophagus-model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:41:46.628573Z","iopub.execute_input":"2023-01-11T12:41:46.628983Z","iopub.status.idle":"2023-01-11T12:41:47.038052Z","shell.execute_reply.started":"2023-01-11T12:41:46.628943Z","shell.execute_reply":"2023-01-11T12:41:47.037066Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from numpy import expand_dims\ndef tta_prediction(datagen, model, image, n_examples):\n    # convert image into dataset\n    samples = expand_dims(image, 0)\n    # prepare iterator\n    it = datagen.flow(samples, batch_size=n_examples)\n    # make predictions for each augmented image\n    probs = model.predict_generator(it, steps=n_examples, verbose=0)\n    #print(len(probs))    \n    prob = np.mean(probs, axis=1)    \n    return prob","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:41:47.039716Z","iopub.execute_input":"2023-01-11T12:41:47.040076Z","iopub.status.idle":"2023-01-11T12:41:47.046512Z","shell.execute_reply.started":"2023-01-11T12:41:47.040041Z","shell.execute_reply":"2023-01-11T12:41:47.045523Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n# configure image data augmentation\ntest_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3, rotation_range=50,\n                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True, fill_mode='nearest')","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:41:47.047829Z","iopub.execute_input":"2023-01-11T12:41:47.048345Z","iopub.status.idle":"2023-01-11T12:41:47.055604Z","shell.execute_reply.started":"2023-01-11T12:41:47.048304Z","shell.execute_reply":"2023-01-11T12:41:47.054649Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test_imgs.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:41:47.057664Z","iopub.execute_input":"2023-01-11T12:41:47.057942Z","iopub.status.idle":"2023-01-11T12:41:47.067112Z","shell.execute_reply.started":"2023-01-11T12:41:47.057893Z","shell.execute_reply":"2023-01-11T12:41:47.066165Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(853, 128, 128, 3)"},"metadata":{}}]},{"cell_type":"code","source":"targetvalues=[]\n#i = 0\nfor img in tqdm(test_imgs):\n    prediction=tta_prediction(test_datagen,model,img,32)\n    pred_y = prediction[0]\n    val=0\n    if pred_y>0.5:\n        val=1\n    targetvalues.append(val)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:41:47.069843Z","iopub.execute_input":"2023-01-11T12:41:47.070108Z","iopub.status.idle":"2023-01-11T12:42:36.192824Z","shell.execute_reply.started":"2023-01-11T12:41:47.070085Z","shell.execute_reply":"2023-01-11T12:42:36.1919Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"  0%|          | 0/853 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:2035: UserWarning:\n\n`Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n\n100%|██████████| 853/853 [00:49<00:00, 17.37it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\nimport sklearn.metrics as metrics\ncm=confusion_matrix(y_test, targetvalues)\ncm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [\"No Cancer\", \"Cancer\"])\ncm_display.plot()\nprint(classification_report(y_test, targetvalues))","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:49:41.568893Z","iopub.execute_input":"2023-01-11T12:49:41.569268Z","iopub.status.idle":"2023-01-11T12:49:41.943106Z","shell.execute_reply.started":"2023-01-11T12:49:41.569236Z","shell.execute_reply":"2023-01-11T12:49:41.942187Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       723\n           1       0.99      0.99      0.99       130\n\n    accuracy                           1.00       853\n   macro avg       1.00      1.00      1.00       853\nweighted avg       1.00      1.00      1.00       853\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"Manual Testing","metadata":{}},{"cell_type":"code","source":"from PIL import Image\ndef preprocess_image(image_path, desired_size=128):\n    im = Image.open(image_path)\n    im = im.resize((desired_size, )*2, resample=Image.LANCZOS)\n    return im","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:42:36.210787Z","iopub.execute_input":"2023-01-11T12:42:36.211107Z","iopub.status.idle":"2023-01-11T12:42:36.216559Z","shell.execute_reply.started":"2023-01-11T12:42:36.211066Z","shell.execute_reply":"2023-01-11T12:42:36.215475Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import os\nesotest = '/kaggle/input/esophagustestset/test/esophagus'\nnoesotest = '/kaggle/input/esophagustestset/test/no-esophagus'\nesotestlist = os.listdir(esotest)\nnoesotestlist = os.listdir(noesotest)\ntestlist = []\nfor name in esotestlist:\n    testlist.append(esotest+'/'+name)\nfor name in noesotestlist:\n    testlist.append(noesotest+'/'+name)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:42:36.218489Z","iopub.execute_input":"2023-01-11T12:42:36.218972Z","iopub.status.idle":"2023-01-11T12:42:36.244914Z","shell.execute_reply.started":"2023-01-11T12:42:36.218932Z","shell.execute_reply":"2023-01-11T12:42:36.243885Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"testlabels = []\nfor i in range(40):\n    if i<20:\n        testlabels.append(1)\n    else:\n        testlabels.append(0)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:42:36.246287Z","iopub.execute_input":"2023-01-11T12:42:36.246628Z","iopub.status.idle":"2023-01-11T12:42:36.252315Z","shell.execute_reply.started":"2023-01-11T12:42:36.246593Z","shell.execute_reply":"2023-01-11T12:42:36.25141Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"N = 40\nimSize = 128\n# create an empty matrix for storing the images\ntestset = np.empty((40, imSize, imSize, 3), dtype=np.uint8)\n\n# loop through the images from the images ids from the target\\id dataset\n# then grab the cooresponding image from disk, pre-process, and store in matrix in memory\nfor i, image_id in enumerate(tqdm(testlist)):\n    testset[i, :, :, :] = preprocess_image(\n        image_id\n    )","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:42:36.253848Z","iopub.execute_input":"2023-01-11T12:42:36.254613Z","iopub.status.idle":"2023-01-11T12:42:37.786963Z","shell.execute_reply.started":"2023-01-11T12:42:36.254576Z","shell.execute_reply":"2023-01-11T12:42:37.785928Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"  0%|          | 0/40 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning:\n\nLANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n\n100%|██████████| 40/40 [00:01<00:00, 26.27it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"predval = []\nfor img in tqdm(testset):\n    prediction=tta_prediction(test_datagen,model,img,1)\n    pred_y = prediction[0]\n    val=0\n    if pred_y>0.5:\n        val=1\n    predval.append(val)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:42:37.788235Z","iopub.execute_input":"2023-01-11T12:42:37.789087Z","iopub.status.idle":"2023-01-11T12:42:40.232762Z","shell.execute_reply.started":"2023-01-11T12:42:37.789051Z","shell.execute_reply":"2023-01-11T12:42:40.231776Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"  0%|          | 0/40 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:2035: UserWarning:\n\n`Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n\n100%|██████████| 40/40 [00:02<00:00, 16.44it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Testing the model accuracy manually","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\nprint(accuracy_score(testlabels,predval)*100)\nprint(confusion_matrix(testlabels, predval))","metadata":{"execution":{"iopub.status.busy":"2023-01-11T12:42:40.233984Z","iopub.execute_input":"2023-01-11T12:42:40.23449Z","iopub.status.idle":"2023-01-11T12:42:40.243895Z","shell.execute_reply.started":"2023-01-11T12:42:40.23445Z","shell.execute_reply":"2023-01-11T12:42:40.242915Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"87.5\n[[18  2]\n [ 3 17]]\n","output_type":"stream"}]}]}